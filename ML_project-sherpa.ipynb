{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50ad4ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "#from tensorflow.contrib import rnn\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Masking, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe4d8c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "\n",
    "#input\n",
    "input_data = pd.read_csv('/Users/Madi/Desktop/ML/inputdata_randomized5time.csv')\n",
    "input_data.head()\n",
    "\n",
    "data1979 = input_data.loc[input_data['year']==1979];data1980 = input_data.loc[input_data['year']==1980];data1981 = input_data.loc[input_data['year']==1981];data1984 = input_data.loc[input_data['year']==1984];data1985 = input_data.loc[input_data['year']==1985];data1986 = input_data.loc[input_data['year']==1986]\n",
    "data1987 = input_data.loc[input_data['year']==1987];data1988 = input_data.loc[input_data['year']==1988];data1989 = input_data.loc[input_data['year'] == 1989];data1990 = input_data.loc[input_data['year'] == 1990];data1992 = input_data.loc[input_data['year']==1992]\n",
    "data1993 = input_data.loc[input_data['year']==1993];data1998 = input_data.loc[input_data['year'] == 1998]\n",
    "data1997 = input_data.loc[input_data['year'] == 1997];data1999 = input_data.loc[input_data['year'] == 1999]; data2000 = input_data.loc[input_data['year'] == 2000]\n",
    "data2001 = input_data.loc[input_data['year'] == 2001]; data2002 = input_data.loc[input_data['year'] == 2002]\n",
    "data2003 = input_data.loc[input_data['year'] == 2003]; data2004 = input_data.loc[input_data['year'] == 2004]\n",
    "data2005 = input_data.loc[input_data['year'] == 2005];data2006 = input_data.loc[input_data['year'] == 2006]\n",
    "data2007 = input_data.loc[input_data['year'] == 2007];data2008 = input_data.loc[input_data['year'] == 2008]\n",
    "data2009 = input_data.loc[input_data['year'] == 2009];data2010 = input_data.loc[input_data['year'] == 2010]\n",
    "data2011 = input_data.loc[input_data['year'] == 2011];data2012 = input_data.loc[input_data['year'] == 2012]\n",
    "data2013 = input_data.loc[input_data['year'] == 2013];data2014 = input_data.loc[input_data['year'] == 2014]\n",
    "data2015 = input_data.loc[input_data['year'] == 2015];data2016 = input_data.loc[input_data['year'] == 2016]\n",
    "data2016 = input_data.loc[input_data['year'] == 2016];data2017 = input_data.loc[input_data['year'] == 2017]\n",
    "data2018 = input_data.loc[input_data['year'] == 2018];data2019 = input_data.loc[input_data['year'] == 2019]\n",
    "data2020 = input_data.loc[input_data['year'] == 2020]\n",
    "\n",
    "\n",
    "\n",
    "a = ['site','latitude','longitude','airT','precip','snowDepth','SWE','streamFlow']\n",
    "\n",
    "data1979= data1979[a].copy();data1980= data1980[a].copy();data1981= data1981[a].copy();data1984= data1984[a].copy();data1985= data1985[a].copy();data1987= data1987[a].copy();data1986= data1986[a].copy();data1988 = data1988[a].copy();data1989 = data1989[a].copy();data1990 = data1990[a].copy() ; data1992 = data1992[a].copy();data1993 = data1993[a].copy();data1998 = data1998[a].copy() \n",
    "data1997 = data1997[a].copy();data1999 = data1999[a].copy();data2000 = data2000[a].copy();data2001 = data2001[a].copy();data2002 = data2002[a].copy()\n",
    "data2007 = data2007[a].copy();data2008 = data2008[a].copy();data2009 = data2009[a].copy()\n",
    "data2010 = data2010[a].copy();data2011 = data2011[a].copy();data2012 = data2012[a].copy()\n",
    "data2013 = data2013[a].copy();data2014 = data2014[a].copy();data2015 = data2015[a].copy()\n",
    "data2016 = data2016[a].copy();data2017 = data2017[a].copy();data2018 = data2018[a].copy()\n",
    "data2019 = data2019[a].copy();data2020 = data2020[a].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c82280da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>D2Area</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>arizona area</th>\n",
       "      <th>california</th>\n",
       "      <th>colorado area</th>\n",
       "      <th>area nevada</th>\n",
       "      <th>new mexico</th>\n",
       "      <th>utah</th>\n",
       "      <th>wyoming</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1979</td>\n",
       "      <td>0.004874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113998.0</td>\n",
       "      <td>163696.000000</td>\n",
       "      <td>104185.0</td>\n",
       "      <td>110567.0</td>\n",
       "      <td>121697.000000</td>\n",
       "      <td>84899.0</td>\n",
       "      <td>97914.0</td>\n",
       "      <td>796956.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980</td>\n",
       "      <td>0.061005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1981</td>\n",
       "      <td>0.017254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>0.230748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>0.004874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1984</td>\n",
       "      <td>0.045597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>0.061005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1985</td>\n",
       "      <td>0.231000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>0.027079</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>0.017254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year    D2Area  Unnamed: 2  Unnamed: 3  Unnamed: 4  arizona area   \\\n",
       "0  1979  0.004874         NaN         NaN         NaN       113998.0   \n",
       "1  1980  0.061005         NaN         NaN         NaN            NaN   \n",
       "2  1981  0.017254         NaN         NaN         NaN         1985.0   \n",
       "3  1984  0.045597         NaN         NaN         NaN         1986.0   \n",
       "4  1985  0.231000         NaN         NaN         NaN         1987.0   \n",
       "\n",
       "      california  colorado area  area nevada     new mexico    utah   \\\n",
       "0  163696.000000       104185.0     110567.0  121697.000000  84899.0   \n",
       "1            NaN            NaN          NaN            NaN      NaN   \n",
       "2       0.230748            NaN       1979.0       0.004874      NaN   \n",
       "3       0.001083            NaN       1980.0       0.061005      NaN   \n",
       "4       0.027079            NaN       1981.0       0.017254      NaN   \n",
       "\n",
       "   wyoming      total  \n",
       "0   97914.0  796956.0  \n",
       "1       NaN       NaN  \n",
       "2       NaN       NaN  \n",
       "3       NaN       NaN  \n",
       "4       NaN       NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#output\n",
    "output_data = pd.read_csv('/Users/Madi/Desktop/ML/cleandroughtdata4.csv')\n",
    "out = [\"D2Area\"]\n",
    "output_labels = output_data[out].copy()\n",
    "output_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92248874",
   "metadata": {},
   "source": [
    "## Organize data manually into batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a66ca45",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "alldata = [data1979,data1980,data1981,data1984,data1985,data1986,data1987,data1988,data1989,data1990,data1992,data1993,data1997,data1998,data1999,data2000,data2001,data2002,data2003,data2004,data2005,data2006,data2007,data2008,data2009,data2010,data2011,data2012,data2013,data2014,data2015,data2016,data2017,data2018,data2019,data2020]\n",
    "\n",
    "#for x in range(len(alldata)):\n",
    " #   print(len(alldata[x])/5)\n",
    "\n",
    "    \n",
    "\n",
    "features = 5\n",
    "batch_size = 4\n",
    "timestep = 5\n",
    "count = 0\n",
    "batch = []\n",
    "tempbatch = []\n",
    "tempyear = []\n",
    "fullbatch = []\n",
    "tracker = 0\n",
    "totalcount = 0\n",
    "\n",
    "\n",
    "for x in range(len(alldata)): \n",
    "    tempyear = alldata[tracker]\n",
    "    batch = []\n",
    "    index=0\n",
    "    for y in range((int(tempyear.shape[0]/timestep))):\n",
    "        if len(batch) < batch_size:\n",
    "            tempbatch = []\n",
    "            if y == (int(tempyear.shape[0]/timestep)-1):\n",
    "                for z in range(timestep):\n",
    "                    tempbatch.append(tempyear.iloc[index])\n",
    "                    index +=1\n",
    "                batch.append(tempbatch)\n",
    "                totalcount +=1\n",
    "                fullbatch.append(batch)\n",
    "            else:\n",
    "                for z in range(timestep):\n",
    "                    tempbatch.append(tempyear.iloc[index])\n",
    "                    index +=1\n",
    "                batch.append(tempbatch)\n",
    "                totalcount +=1\n",
    "\n",
    "        elif len(batch) == batch_size:\n",
    "            fullbatch.append(batch)\n",
    "            batch = []\n",
    "            tempbatch = []\n",
    "            for z in range(timestep):\n",
    "                tempbatch.append(tempyear.iloc[index])\n",
    "                if index == (tempyear.shape[0]-1):\n",
    "                    batch.append(tempbatch)\n",
    "                    fullbatch.append(batch)\n",
    "                    batch = []\n",
    "                index +=1\n",
    "   \n",
    "            batch.append(tempbatch)\n",
    "            \n",
    "    tracker +=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2f3915",
   "metadata": {},
   "source": [
    "## Add Padding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4623607",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#prepadding so batch size is uniform\n",
    "onesite = []\n",
    "\n",
    "pad = [[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]]\n",
    "\n",
    "for x in range(len(fullbatch)):\n",
    "    single = fullbatch[x]\n",
    "    for m in range(len(single)):\n",
    "        if len(single) != batch_size:\n",
    "            difference = batch_size - len(single)\n",
    "            while difference != 0:\n",
    "                for k in range(difference):\n",
    "                    single.insert(0,pad)\n",
    "                    difference = batch_size - len(single)\n",
    "         \n",
    "\n",
    "\n",
    "#convert data back into dataframe\n",
    "newbatch = []\n",
    "for x in range(len(fullbatch)):\n",
    "    single = fullbatch[x]\n",
    "    for c in range(len(single)):\n",
    "        individual = single[c]\n",
    "        for d in range(len(individual)):\n",
    "            one = individual[d]\n",
    "            one = pd.DataFrame(one)\n",
    "            one = pd.DataFrame.transpose(one)\n",
    "\n",
    "                   \n",
    "\n",
    "for x in range(len(fullbatch)):\n",
    "    single = fullbatch[x]\n",
    "    for c in range(len(single)):\n",
    "        individual = single[c]\n",
    "        for d in range(len(individual)):\n",
    "            one = individual[d]\n",
    "            if isinstance(one,list) == False:\n",
    "                one = one.tolist()\n",
    "                one.pop(0)\n",
    "                if len(one) != features:\n",
    "                    while len(one) != features:\n",
    "                        one.pop(0)\n",
    "                newbatch.append(one)\n",
    "            else:\n",
    "                newbatch.append(one)\n",
    "                 \n",
    "paddedfinal = pd.DataFrame(newbatch,columns=['airT','precip','snowDepth','SWE','streamFlow'])\n",
    "\n",
    "#print(paddedfinal.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "805af078",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## reorganize data so a batch of sites per each timestep is a single vector\n",
    "\n",
    "temp = []\n",
    "batches = []\n",
    "index = 0\n",
    "paddedfarray = paddedfinal.values.tolist()\n",
    "\n",
    "padded_flatten = list(itertools.chain(*paddedfarray))\n",
    "\n",
    "\n",
    "for y in range(int(len(paddedfarray)/batch_size/timestep)):\n",
    "    for x in range(timestep*batch_size):\n",
    "        temp.append(paddedfarray[index])\n",
    "        index +=1\n",
    "    batches.append(temp)\n",
    "    temp = []\n",
    "\n",
    "\n",
    "batch = []\n",
    "combined = []\n",
    "\n",
    "\n",
    "for y in range(len(batches)):\n",
    "    index = 0\n",
    "    count = 0\n",
    "    batch = batches[y]\n",
    "    for z in range(int(len(batch)/batch_size)):\n",
    "        for x in range(batch_size):\n",
    "            temp.append(batch[index])\n",
    "            index +=timestep\n",
    "        combined.append(temp)\n",
    "        temp = []\n",
    "        count+=1\n",
    "        index = count\n",
    "        \n",
    "for x in range(len(combined)):\n",
    "    combined[x] = list(itertools.chain(*combined[x]))\n",
    "  \n",
    "#print(len(combined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20846432",
   "metadata": {},
   "outputs": [],
   "source": [
    "z= features*batch_size\n",
    "\n",
    "reshapedcombined = np.reshape(combined,(int(len(combined)/timestep),timestep,z))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(reshapedcombined, output_labels, test_size=0.30, random_state=117)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24472848",
   "metadata": {},
   "source": [
    "## Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "658bb58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize data\n",
    "\n",
    "x_mean = X_train.mean(axis=0)\n",
    "x_std = X_train.std(axis=0)\n",
    "X_train = (X_train - x_mean) / x_std # (train_data - min) / (max-min) \n",
    "X_test = (X_test - x_mean) / x_std\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db05761f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(211, 5, 20) \n",
      " (211, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,'\\n',y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ea8344",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1822306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sherpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e2a7d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sherpa.core:\n",
      "-------------------------------------------------------\n",
      "SHERPA Dashboard running. Access via\n",
      "http://209.2.224.182:8880 if on a cluster or\n",
      "http://localhost:8880 if running locally.\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app 'sherpa.app.app' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:werkzeug: * Running on all addresses.\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n"
     ]
    }
   ],
   "source": [
    "parameters = [sherpa.Continuous(name='lr', range=[0.0005, 0.001], scale='log'),\n",
    "sherpa.Ordinal(name='dropout', range=[0,0.1,0.2,0.3, 0.4,0.5]),\n",
    "    sherpa.Ordinal(name='numnodes',range=[8,16,32,64,128]),\n",
    "    sherpa.Discrete(name='numlayers',range=[1,8])]\n",
    "\n",
    "\n",
    "num_trials = 500\n",
    "alg = sherpa.algorithms.RandomSearch(max_num_trials=num_trials)\n",
    "\n",
    "study = sherpa.Study(parameters=parameters,\n",
    "                     algorithm=alg,\n",
    "                     lower_is_better=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "800747c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1:\t{'lr': 0.000571544771677448, 'dropout': 0.5, 'numnodes': 128, 'numlayers': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-20 15:41:28.342174: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-20 15:41:29.947579: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xc/79twkv8x7jbg7n35q26jvhzw0000gn/T/ipykernel_8112/1283880502.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mae'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     study.add_observation(trial=trial, \n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m                     \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m                     \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m                     \u001b[0muser_requested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m                 ))\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    477\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m    797\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1257\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1258\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1259\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2728\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2730\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2732\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3415\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3416\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3417\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3419\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m       \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m       loss = self.compiled_loss(\n\u001b[1;32m    756\u001b[0m           y, y_pred, sample_weight, regularization_losses=self.losses)\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    373\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[0;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \"\"\"\n\u001b[1;32m    424\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 425\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m   1268\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m           (last_output, outputs, new_h, new_c,\n\u001b[0;32m-> 1270\u001b[0;31m            runtime) = lstm_with_backend_selection(**normal_lstm_kwargs)\n\u001b[0m\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m       \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mlstm_with_backend_selection\u001b[0;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask)\u001b[0m\n\u001b[1;32m   1653\u001b[0m     \u001b[0;31m# Call the normal LSTM impl and register the CuDNN impl function. The\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m     \u001b[0;31m# grappler will kick in during session execution to optimize the graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1655\u001b[0;31m     \u001b[0mlast_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefun_standard_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1656\u001b[0m     \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_gpu_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mstandard_lstm\u001b[0;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask)\u001b[0m\n\u001b[1;32m   1400\u001b[0m       input_length=(sequence_lengths\n\u001b[1;32m   1401\u001b[0m                     if sequence_lengths is not None else timesteps),\n\u001b[0;32m-> 1402\u001b[0;31m       zero_output_for_mask=zero_output_for_mask)\n\u001b[0m\u001b[1;32m   1403\u001b[0m   return (last_output, outputs, new_states[0], new_states[1],\n\u001b[1;32m   1404\u001b[0m           _runtime(_RUNTIME_CPU))\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask)\u001b[0m\n\u001b[1;32m   4494\u001b[0m           \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4495\u001b[0m           \u001b[0mloop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_ta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4496\u001b[0;31m           **while_loop_kwargs)\n\u001b[0m\u001b[1;32m   4497\u001b[0m       \u001b[0mnew_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m         \u001b[0mreturn_same_structure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_same_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2696\u001b[0;31m         back_prop=back_prop)\n\u001b[0m\u001b[1;32m   2697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2698\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"while\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, maximum_iterations, name, return_same_structure, back_prop)\u001b[0m\n\u001b[1;32m    149\u001b[0m         func_graph=util.WhileCondFuncGraph(\n\u001b[1;32m    150\u001b[0m             cond_name, collections=ops.get_default_graph()._collections),  # pylint: disable=protected-access\n\u001b[0;32m--> 151\u001b[0;31m         add_control_dependencies=add_control_dependencies)\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_counter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaximum_iterations_arg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36mwrapped_cond\u001b[0;34m(loop_counter, maximum_iterations_arg, *args)\u001b[0m\n\u001b[1;32m    128\u001b[0m       \u001b[0;31m# `orig_loop_vars` and `args`, converts flows in `args` to TensorArrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m       \u001b[0;31m# and packs it into the structure of `orig_loop_vars`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m       \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_pack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_loop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m       if (tensor_util.is_tensor(pred) and\n\u001b[1;32m    132\u001b[0m           (pred.shape.dims is None or pred.shape.dims)):\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(time, *_)\u001b[0m\n\u001b[1;32m   4367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4368\u001b[0m     while_loop_kwargs = {\n\u001b[0;32m-> 4369\u001b[0;31m         \u001b[0;34m'cond'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtime_steps_t\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4370\u001b[0m         \u001b[0;34m'maximum_iterations'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmax_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4371\u001b[0m         \u001b[0;34m'parallel_iterations'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mless\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   4847\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4848\u001b[0m     _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0;32m-> 4849\u001b[0;31m         \"Less\", x=x, y=y, name=name)\n\u001b[0m\u001b[1;32m   4850\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4851\u001b[0m     result = _dispatch.dispatch(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    748\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[1;32m    749\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    590\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    591\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3534\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3535\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3536\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3537\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3538\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1988\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1989\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1990\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1992\u001b[0m     \u001b[0;31m# List of _UserDevSpecs holding code location of device context manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/util/tf_stack.py\u001b[0m in \u001b[0;36mextract_stack\u001b[0;34m(limit)\u001b[0m\n\u001b[1;32m    151\u001b[0m       \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0m_source_mapper_stacks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mthread_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       _source_filter_stacks[thread_key])\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0mStackSummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tf_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStackSummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20,verbose=True)\n",
    " \n",
    "# Define basic architecture\n",
    "for trial in study:\n",
    "    print(\"Trial {}:\\t{}\".format(trial.id, trial.parameters))\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    for i in range(trial.parameters['numlayers']):\n",
    "        model.add(keras.layers.LSTM(trial.parameters['numnodes'], return_sequences=True, input_shape = (timestep,features*batch_size)))\n",
    "        model.add(keras.layers.Dropout(trial.parameters['dropout']))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "   \n",
    "\n",
    "    optimizer = keras.optimizers.Adam(trial.parameters['lr'])\n",
    "    model.compile(loss='mse',optimizer=optimizer, metrics=['mae'])\n",
    "\n",
    "    history = model.fit(X_train,y_train,epochs=1000, validation_split=0.2,callbacks=early_stop,verbose=True)\n",
    "    loss, mae = model.evaluate(X_test,y_test,verbose=0)\n",
    "    study.add_observation(trial=trial, \n",
    "                        objective=mae,\n",
    "                        context={'loss': loss})\n",
    "    \n",
    "    if study.should_trial_stop(trial):\n",
    "        break\n",
    "    study.finalize(trial)\n",
    "\n",
    "    print(study.get_best_result())\n",
    "\n",
    "\n",
    "    \n",
    "   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "54fab0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Trial-ID': 132, 'Iteration': 1, 'dropout': 0.3, 'lr': 0.0009323930094558037, 'numlayers': 7, 'numnodes': 8, 'Objective': 0.18927384912967682, 'loss': 0.05304437503218651}\n"
     ]
    }
   ],
   "source": [
    "print(study.get_best_result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "bbc1767b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrialID</th>\n",
       "      <th>Dropout Rate</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Layers</th>\n",
       "      <th>Nodes</th>\n",
       "      <th>Objective</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>437</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.0499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>345</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.0518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.0530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>372</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.0533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>394</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.0536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>236</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.0538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>404</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.0543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>63</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.0543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>207</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.0544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>426</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.0545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TrialID  Dropout Rate  Learning Rate  Layers  Nodes  Objective    Loss\n",
       "0      437           0.4       0.000781       2      8      0.191  0.0499\n",
       "1      345           0.3       0.000679       2      8      0.193  0.0518\n",
       "2      132           0.3       0.000932       7      8      0.189  0.0530\n",
       "3      372           0.5       0.000826       4     16      0.196  0.0533\n",
       "4      394           0.5       0.000541       2      8      0.199  0.0536\n",
       "5      236           0.5       0.000603       3      8      0.199  0.0538\n",
       "6      404           0.4       0.000687       4      8      0.196  0.0543\n",
       "7       63           0.1       0.000640       2      8      0.195  0.0543\n",
       "8      207           0.4       0.000831       3     16      0.198  0.0544\n",
       "9      426           0.3       0.000624       7      8      0.196  0.0545"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sherpabest = pd.read_csv('/Users/Madi/Desktop/ML/sherparesultsb4.csv')\n",
    "display(sherpabest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "9c021396",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "6/6 [==============================] - 5s 228ms/step - loss: 0.6015 - mae: 0.3269 - val_loss: 0.5544 - val_mae: 0.2934\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.5749 - mae: 0.3209 - val_loss: 0.5276 - val_mae: 0.2786\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.5432 - mae: 0.3046 - val_loss: 0.5028 - val_mae: 0.2659\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.5353 - mae: 0.3063 - val_loss: 0.4796 - val_mae: 0.2550\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.4949 - mae: 0.2764 - val_loss: 0.4578 - val_mae: 0.2453\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.4736 - mae: 0.2678 - val_loss: 0.4371 - val_mae: 0.2359\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.4604 - mae: 0.2724 - val_loss: 0.4180 - val_mae: 0.2280\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.4320 - mae: 0.2507 - val_loss: 0.4001 - val_mae: 0.2209\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.4237 - mae: 0.2566 - val_loss: 0.3831 - val_mae: 0.2143\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.4034 - mae: 0.2507 - val_loss: 0.3671 - val_mae: 0.2088\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3882 - mae: 0.2462 - val_loss: 0.3521 - val_mae: 0.2043\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.3733 - mae: 0.2412 - val_loss: 0.3380 - val_mae: 0.2007\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.3559 - mae: 0.2310 - val_loss: 0.3247 - val_mae: 0.1977\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.3451 - mae: 0.2291 - val_loss: 0.3121 - val_mae: 0.1951\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.3342 - mae: 0.2317 - val_loss: 0.3002 - val_mae: 0.1932\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.3244 - mae: 0.2378 - val_loss: 0.2891 - val_mae: 0.1918\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.3101 - mae: 0.2278 - val_loss: 0.2787 - val_mae: 0.1910\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.2902 - mae: 0.2125 - val_loss: 0.2689 - val_mae: 0.1902\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.2942 - mae: 0.2323 - val_loss: 0.2596 - val_mae: 0.1895\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.2789 - mae: 0.2245 - val_loss: 0.2508 - val_mae: 0.1890\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.2671 - mae: 0.2180 - val_loss: 0.2424 - val_mae: 0.1888\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2610 - mae: 0.2224 - val_loss: 0.2344 - val_mae: 0.1885\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.2487 - mae: 0.2136 - val_loss: 0.2268 - val_mae: 0.1882\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 1s 126ms/step - loss: 0.2484 - mae: 0.2265 - val_loss: 0.2194 - val_mae: 0.1879\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.2362 - mae: 0.2171 - val_loss: 0.2125 - val_mae: 0.1877\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.2305 - mae: 0.2215 - val_loss: 0.2058 - val_mae: 0.1876\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2185 - mae: 0.2096 - val_loss: 0.1993 - val_mae: 0.1873\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.2207 - mae: 0.2265 - val_loss: 0.1929 - val_mae: 0.1868\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.2035 - mae: 0.2050 - val_loss: 0.1869 - val_mae: 0.1866\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.2048 - mae: 0.2212 - val_loss: 0.1811 - val_mae: 0.1863\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.1945 - mae: 0.2133 - val_loss: 0.1756 - val_mae: 0.1862\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.1876 - mae: 0.2106 - val_loss: 0.1704 - val_mae: 0.1860\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.1821 - mae: 0.2097 - val_loss: 0.1654 - val_mae: 0.1857\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.1820 - mae: 0.2169 - val_loss: 0.1606 - val_mae: 0.1855\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.1789 - mae: 0.2204 - val_loss: 0.1560 - val_mae: 0.1852\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.1729 - mae: 0.2192 - val_loss: 0.1515 - val_mae: 0.1848\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.1641 - mae: 0.2102 - val_loss: 0.1472 - val_mae: 0.1847\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.1639 - mae: 0.2165 - val_loss: 0.1432 - val_mae: 0.1847\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.1649 - mae: 0.2264 - val_loss: 0.1393 - val_mae: 0.1845\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.1505 - mae: 0.2087 - val_loss: 0.1355 - val_mae: 0.1843\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.1482 - mae: 0.2108 - val_loss: 0.1319 - val_mae: 0.1842\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.1426 - mae: 0.2081 - val_loss: 0.1285 - val_mae: 0.1846\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.1461 - mae: 0.2173 - val_loss: 0.1253 - val_mae: 0.1854\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.1325 - mae: 0.2015 - val_loss: 0.1222 - val_mae: 0.1858\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.1362 - mae: 0.2131 - val_loss: 0.1192 - val_mae: 0.1859\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.1261 - mae: 0.2001 - val_loss: 0.1164 - val_mae: 0.1865\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.1236 - mae: 0.1991 - val_loss: 0.1137 - val_mae: 0.1866\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.1234 - mae: 0.2054 - val_loss: 0.1110 - val_mae: 0.1866\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.1209 - mae: 0.2059 - val_loss: 0.1084 - val_mae: 0.1864\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.1174 - mae: 0.2048 - val_loss: 0.1060 - val_mae: 0.1865\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.1158 - mae: 0.2052 - val_loss: 0.1037 - val_mae: 0.1860\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.1136 - mae: 0.2070 - val_loss: 0.1013 - val_mae: 0.1855\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.1136 - mae: 0.2114 - val_loss: 0.0990 - val_mae: 0.1852\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.1097 - mae: 0.2053 - val_loss: 0.0968 - val_mae: 0.1849\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.1101 - mae: 0.2102 - val_loss: 0.0949 - val_mae: 0.1850\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.1017 - mae: 0.1976 - val_loss: 0.0930 - val_mae: 0.1849\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.1034 - mae: 0.2029 - val_loss: 0.0912 - val_mae: 0.1847\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0978 - mae: 0.1965 - val_loss: 0.0895 - val_mae: 0.1847\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.1015 - mae: 0.2081 - val_loss: 0.0878 - val_mae: 0.1846\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0969 - mae: 0.2048 - val_loss: 0.0863 - val_mae: 0.1847\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0961 - mae: 0.2036 - val_loss: 0.0849 - val_mae: 0.1851\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0921 - mae: 0.1977 - val_loss: 0.0834 - val_mae: 0.1850\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0895 - mae: 0.1972 - val_loss: 0.0821 - val_mae: 0.1853\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0926 - mae: 0.2050 - val_loss: 0.0807 - val_mae: 0.1856\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0872 - mae: 0.1973 - val_loss: 0.0792 - val_mae: 0.1848\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0924 - mae: 0.2114 - val_loss: 0.0779 - val_mae: 0.1848\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0812 - mae: 0.1896 - val_loss: 0.0766 - val_mae: 0.1842\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0894 - mae: 0.2112 - val_loss: 0.0754 - val_mae: 0.1838\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0827 - mae: 0.1965 - val_loss: 0.0744 - val_mae: 0.1840\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0841 - mae: 0.2047 - val_loss: 0.0733 - val_mae: 0.1839\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0831 - mae: 0.2019 - val_loss: 0.0721 - val_mae: 0.1834\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0810 - mae: 0.1969 - val_loss: 0.0712 - val_mae: 0.1836\n",
      "Epoch 73/1000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0846 - mae: 0.2126 - val_loss: 0.0703 - val_mae: 0.1837\n",
      "Epoch 74/1000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0805 - mae: 0.2031 - val_loss: 0.0696 - val_mae: 0.1844\n",
      "Epoch 75/1000\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0791 - mae: 0.2020 - val_loss: 0.0686 - val_mae: 0.1839\n",
      "Epoch 76/1000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0762 - mae: 0.1962 - val_loss: 0.0678 - val_mae: 0.1842\n",
      "Epoch 77/1000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0793 - mae: 0.2069 - val_loss: 0.0672 - val_mae: 0.1848\n",
      "Epoch 78/1000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0732 - mae: 0.1952 - val_loss: 0.0666 - val_mae: 0.1853\n",
      "Epoch 79/1000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0713 - mae: 0.1883 - val_loss: 0.0660 - val_mae: 0.1854\n",
      "Epoch 80/1000\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0740 - mae: 0.1989 - val_loss: 0.0653 - val_mae: 0.1851\n",
      "Epoch 81/1000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0739 - mae: 0.1999 - val_loss: 0.0645 - val_mae: 0.1843\n",
      "Epoch 82/1000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0692 - mae: 0.1920 - val_loss: 0.0639 - val_mae: 0.1838\n",
      "Epoch 83/1000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0703 - mae: 0.1970 - val_loss: 0.0632 - val_mae: 0.1832\n",
      "Epoch 84/1000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0686 - mae: 0.1944 - val_loss: 0.0626 - val_mae: 0.1830\n",
      "Epoch 85/1000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0678 - mae: 0.1906 - val_loss: 0.0623 - val_mae: 0.1835\n",
      "Epoch 86/1000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0682 - mae: 0.1943 - val_loss: 0.0619 - val_mae: 0.1840\n",
      "Epoch 87/1000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0657 - mae: 0.1881 - val_loss: 0.0616 - val_mae: 0.1846\n",
      "Epoch 88/1000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0685 - mae: 0.1978 - val_loss: 0.0612 - val_mae: 0.1849\n",
      "Epoch 89/1000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0642 - mae: 0.1893 - val_loss: 0.0607 - val_mae: 0.1847\n",
      "Epoch 90/1000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0665 - mae: 0.1963 - val_loss: 0.0601 - val_mae: 0.1841\n",
      "Epoch 91/1000\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0621 - mae: 0.1874 - val_loss: 0.0595 - val_mae: 0.1833\n",
      "Epoch 92/1000\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0663 - mae: 0.1969 - val_loss: 0.0591 - val_mae: 0.1832\n",
      "Epoch 93/1000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0649 - mae: 0.1915 - val_loss: 0.0587 - val_mae: 0.1831\n",
      "Epoch 94/1000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0622 - mae: 0.1884 - val_loss: 0.0585 - val_mae: 0.1837\n",
      "Epoch 95/1000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0677 - mae: 0.2002 - val_loss: 0.0584 - val_mae: 0.1847\n",
      "Epoch 96/1000\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0606 - mae: 0.1893 - val_loss: 0.0579 - val_mae: 0.1842\n",
      "Epoch 97/1000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0644 - mae: 0.1951 - val_loss: 0.0575 - val_mae: 0.1838\n",
      "Epoch 98/1000\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0636 - mae: 0.1959 - val_loss: 0.0573 - val_mae: 0.1842\n",
      "Epoch 99/1000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0615 - mae: 0.1916 - val_loss: 0.0571 - val_mae: 0.1841\n",
      "Epoch 100/1000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0643 - mae: 0.1969 - val_loss: 0.0569 - val_mae: 0.1838\n",
      "Epoch 101/1000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0655 - mae: 0.2031 - val_loss: 0.0566 - val_mae: 0.1836\n",
      "Epoch 102/1000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0631 - mae: 0.1960 - val_loss: 0.0562 - val_mae: 0.1835\n",
      "Epoch 103/1000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0637 - mae: 0.1975 - val_loss: 0.0561 - val_mae: 0.1843\n",
      "Epoch 104/1000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0603 - mae: 0.1919 - val_loss: 0.0558 - val_mae: 0.1842\n",
      "Epoch 105/1000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0583 - mae: 0.1894 - val_loss: 0.0554 - val_mae: 0.1838\n",
      "Epoch 106/1000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0643 - mae: 0.2011 - val_loss: 0.0548 - val_mae: 0.1833\n",
      "Epoch 107/1000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0594 - mae: 0.1902 - val_loss: 0.0544 - val_mae: 0.1825\n",
      "Epoch 108/1000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0605 - mae: 0.1937 - val_loss: 0.0544 - val_mae: 0.1828\n",
      "Epoch 109/1000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0600 - mae: 0.1958 - val_loss: 0.0544 - val_mae: 0.1836\n",
      "Epoch 110/1000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0579 - mae: 0.1891 - val_loss: 0.0544 - val_mae: 0.1843\n",
      "Epoch 111/1000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0611 - mae: 0.1964 - val_loss: 0.0543 - val_mae: 0.1845\n",
      "Epoch 112/1000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0575 - mae: 0.1906 - val_loss: 0.0540 - val_mae: 0.1844\n",
      "Epoch 113/1000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0555 - mae: 0.1871 - val_loss: 0.0539 - val_mae: 0.1839\n",
      "Epoch 114/1000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0609 - mae: 0.1969 - val_loss: 0.0539 - val_mae: 0.1839\n",
      "Epoch 115/1000\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0557 - mae: 0.1866 - val_loss: 0.0544 - val_mae: 0.1850\n",
      "Epoch 116/1000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0596 - mae: 0.1931 - val_loss: 0.0544 - val_mae: 0.1852\n",
      "Epoch 117/1000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0585 - mae: 0.1913 - val_loss: 0.0540 - val_mae: 0.1847\n",
      "Epoch 118/1000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0561 - mae: 0.1893 - val_loss: 0.0537 - val_mae: 0.1841\n",
      "Epoch 119/1000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0588 - mae: 0.1950 - val_loss: 0.0534 - val_mae: 0.1835\n",
      "Epoch 120/1000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0580 - mae: 0.1908 - val_loss: 0.0528 - val_mae: 0.1825\n",
      "Epoch 121/1000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0589 - mae: 0.1940 - val_loss: 0.0524 - val_mae: 0.1818\n",
      "Epoch 122/1000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0538 - mae: 0.1834 - val_loss: 0.0523 - val_mae: 0.1818\n",
      "Epoch 123/1000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0567 - mae: 0.1914 - val_loss: 0.0523 - val_mae: 0.1815\n",
      "Epoch 124/1000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0563 - mae: 0.1876 - val_loss: 0.0522 - val_mae: 0.1816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/1000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0574 - mae: 0.1900 - val_loss: 0.0520 - val_mae: 0.1815\n",
      "Epoch 126/1000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0570 - mae: 0.1909 - val_loss: 0.0518 - val_mae: 0.1813\n",
      "Epoch 127/1000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0536 - mae: 0.1858 - val_loss: 0.0514 - val_mae: 0.1807\n",
      "Epoch 128/1000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0578 - mae: 0.1955 - val_loss: 0.0515 - val_mae: 0.1811\n",
      "Epoch 129/1000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0553 - mae: 0.1893 - val_loss: 0.0516 - val_mae: 0.1815\n",
      "Epoch 130/1000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0572 - mae: 0.1943 - val_loss: 0.0517 - val_mae: 0.1817\n",
      "Epoch 131/1000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0554 - mae: 0.1887 - val_loss: 0.0517 - val_mae: 0.1821\n",
      "Epoch 132/1000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0541 - mae: 0.1882 - val_loss: 0.0516 - val_mae: 0.1821\n",
      "Epoch 133/1000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0533 - mae: 0.1854 - val_loss: 0.0518 - val_mae: 0.1833\n",
      "Epoch 134/1000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0562 - mae: 0.1933 - val_loss: 0.0519 - val_mae: 0.1839\n",
      "Epoch 135/1000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0549 - mae: 0.1868 - val_loss: 0.0519 - val_mae: 0.1844\n",
      "Epoch 136/1000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0532 - mae: 0.1869 - val_loss: 0.0518 - val_mae: 0.1842\n",
      "Epoch 137/1000\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0562 - mae: 0.1943 - val_loss: 0.0513 - val_mae: 0.1824\n",
      "Epoch 138/1000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0583 - mae: 0.1972 - val_loss: 0.0511 - val_mae: 0.1817\n",
      "Epoch 139/1000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0504 - mae: 0.1799 - val_loss: 0.0514 - val_mae: 0.1826\n",
      "Epoch 140/1000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0530 - mae: 0.1855 - val_loss: 0.0518 - val_mae: 0.1844\n",
      "Epoch 141/1000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0535 - mae: 0.1893 - val_loss: 0.0524 - val_mae: 0.1866\n",
      "Epoch 142/1000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0535 - mae: 0.1886 - val_loss: 0.0524 - val_mae: 0.1873\n",
      "Epoch 143/1000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0556 - mae: 0.1938 - val_loss: 0.0519 - val_mae: 0.1862\n",
      "Epoch 144/1000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0540 - mae: 0.1899 - val_loss: 0.0516 - val_mae: 0.1853\n",
      "Epoch 145/1000\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0539 - mae: 0.1909 - val_loss: 0.0514 - val_mae: 0.1850\n",
      "Epoch 146/1000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0561 - mae: 0.1942 - val_loss: 0.0511 - val_mae: 0.1844\n",
      "Epoch 147/1000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0537 - mae: 0.1918 - val_loss: 0.0507 - val_mae: 0.1834\n",
      "Epoch 148/1000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0559 - mae: 0.1958 - val_loss: 0.0502 - val_mae: 0.1816\n",
      "Epoch 149/1000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0562 - mae: 0.1953 - val_loss: 0.0500 - val_mae: 0.1806\n",
      "Epoch 150/1000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0520 - mae: 0.1839 - val_loss: 0.0500 - val_mae: 0.1808\n",
      "Epoch 151/1000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0559 - mae: 0.1940 - val_loss: 0.0499 - val_mae: 0.1802\n",
      "Epoch 152/1000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0554 - mae: 0.1902 - val_loss: 0.0499 - val_mae: 0.1802\n",
      "Epoch 153/1000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0541 - mae: 0.1897 - val_loss: 0.0496 - val_mae: 0.1791\n",
      "Epoch 154/1000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0551 - mae: 0.1925 - val_loss: 0.0495 - val_mae: 0.1788\n",
      "Epoch 155/1000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0543 - mae: 0.1912 - val_loss: 0.0496 - val_mae: 0.1792\n",
      "Epoch 156/1000\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0540 - mae: 0.1882 - val_loss: 0.0495 - val_mae: 0.1793\n",
      "Epoch 157/1000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0544 - mae: 0.1896 - val_loss: 0.0494 - val_mae: 0.1793\n",
      "Epoch 158/1000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0530 - mae: 0.1895 - val_loss: 0.0493 - val_mae: 0.1792\n",
      "Epoch 159/1000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0556 - mae: 0.1938 - val_loss: 0.0495 - val_mae: 0.1801\n",
      "Epoch 160/1000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0550 - mae: 0.1917 - val_loss: 0.0496 - val_mae: 0.1809\n",
      "Epoch 161/1000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0530 - mae: 0.1894 - val_loss: 0.0496 - val_mae: 0.1813\n",
      "Epoch 162/1000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0555 - mae: 0.1947 - val_loss: 0.0500 - val_mae: 0.1824\n",
      "Epoch 163/1000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0533 - mae: 0.1893 - val_loss: 0.0501 - val_mae: 0.1830\n",
      "Epoch 164/1000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0540 - mae: 0.1903 - val_loss: 0.0499 - val_mae: 0.1827\n",
      "Epoch 165/1000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0542 - mae: 0.1908 - val_loss: 0.0497 - val_mae: 0.1820\n",
      "Epoch 166/1000\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0514 - mae: 0.1844 - val_loss: 0.0498 - val_mae: 0.1826\n",
      "Epoch 167/1000\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0521 - mae: 0.1847 - val_loss: 0.0499 - val_mae: 0.1821\n",
      "Epoch 168/1000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0553 - mae: 0.1915 - val_loss: 0.0498 - val_mae: 0.1812\n",
      "Epoch 169/1000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0555 - mae: 0.1950 - val_loss: 0.0498 - val_mae: 0.1812\n",
      "Epoch 170/1000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0492 - mae: 0.1814 - val_loss: 0.0496 - val_mae: 0.1808\n",
      "Epoch 171/1000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0497 - mae: 0.1832 - val_loss: 0.0499 - val_mae: 0.1816\n",
      "Epoch 172/1000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0551 - mae: 0.1947 - val_loss: 0.0497 - val_mae: 0.1813\n",
      "Epoch 173/1000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0509 - mae: 0.1834 - val_loss: 0.0495 - val_mae: 0.1813\n",
      "Epoch 174/1000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0550 - mae: 0.1950 - val_loss: 0.0494 - val_mae: 0.1810\n",
      "Epoch 175/1000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0518 - mae: 0.1862 - val_loss: 0.0493 - val_mae: 0.1810\n",
      "Epoch 176/1000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0549 - mae: 0.1941 - val_loss: 0.0493 - val_mae: 0.1808\n",
      "Epoch 177/1000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0575 - mae: 0.1978 - val_loss: 0.0494 - val_mae: 0.1814\n",
      "Epoch 178/1000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0520 - mae: 0.1887 - val_loss: 0.0492 - val_mae: 0.1807\n",
      "Epoch 179/1000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0516 - mae: 0.1875 - val_loss: 0.0493 - val_mae: 0.1810\n",
      "Epoch 180/1000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0497 - mae: 0.1812 - val_loss: 0.0497 - val_mae: 0.1819\n",
      "Epoch 181/1000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0524 - mae: 0.1883 - val_loss: 0.0500 - val_mae: 0.1824\n",
      "Epoch 182/1000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0510 - mae: 0.1867 - val_loss: 0.0497 - val_mae: 0.1813\n",
      "Epoch 183/1000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0523 - mae: 0.1884 - val_loss: 0.0499 - val_mae: 0.1817\n",
      "Epoch 184/1000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0515 - mae: 0.1862 - val_loss: 0.0502 - val_mae: 0.1827\n",
      "Epoch 185/1000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0498 - mae: 0.1829 - val_loss: 0.0503 - val_mae: 0.1834\n",
      "Epoch 186/1000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0528 - mae: 0.1899 - val_loss: 0.0504 - val_mae: 0.1837\n",
      "Epoch 187/1000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0560 - mae: 0.1939 - val_loss: 0.0505 - val_mae: 0.1844\n",
      "Epoch 188/1000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0530 - mae: 0.1894 - val_loss: 0.0506 - val_mae: 0.1844\n",
      "Epoch 189/1000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0529 - mae: 0.1890 - val_loss: 0.0503 - val_mae: 0.1834\n",
      "Epoch 190/1000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0538 - mae: 0.1921 - val_loss: 0.0500 - val_mae: 0.1823\n",
      "Epoch 191/1000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0531 - mae: 0.1892 - val_loss: 0.0497 - val_mae: 0.1814\n",
      "Epoch 192/1000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0503 - mae: 0.1825 - val_loss: 0.0495 - val_mae: 0.1809\n",
      "Epoch 193/1000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0532 - mae: 0.1887 - val_loss: 0.0495 - val_mae: 0.1810\n",
      "Epoch 194/1000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0507 - mae: 0.1849 - val_loss: 0.0492 - val_mae: 0.1809\n",
      "Epoch 195/1000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0548 - mae: 0.1932 - val_loss: 0.0495 - val_mae: 0.1821\n",
      "Epoch 196/1000\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0508 - mae: 0.1866 - val_loss: 0.0494 - val_mae: 0.1825\n",
      "Epoch 197/1000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0508 - mae: 0.1853 - val_loss: 0.0493 - val_mae: 0.1823\n",
      "Epoch 198/1000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0511 - mae: 0.1840 - val_loss: 0.0492 - val_mae: 0.1819\n",
      "Epoch 00198: early stopping\n",
      "Model: \"sequential_930\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3813 (LSTM)             (None, 5, 8)              1184      \n",
      "_________________________________________________________________\n",
      "dropout_3813 (Dropout)       (None, 5, 8)              0         \n",
      "_________________________________________________________________\n",
      "lstm_3814 (LSTM)             (None, 5, 8)              544       \n",
      "_________________________________________________________________\n",
      "dropout_3814 (Dropout)       (None, 5, 8)              0         \n",
      "_________________________________________________________________\n",
      "dense_930 (Dense)            (None, 5, 1)              9         \n",
      "=================================================================\n",
      "Total params: 1,737\n",
      "Trainable params: 1,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "layers = 2\n",
    "nodes = 8\n",
    "dropout = 0.5\n",
    "lr = 0.0008\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20,verbose=True)\n",
    "# We want to use this data to determine how long to train before the model stops making progress.\n",
    "def plot_history(history):\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Abs Error')\n",
    "    plt.plot(history.epoch, np.array(history.history['loss']),\n",
    "           label='Train Loss')\n",
    "    plt.plot(history.epoch, np.array(history.history['val_loss']),\n",
    "           label = 'Val Loss')\n",
    "    plt.legend() \n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "for i in range(layers):\n",
    "    model.add(keras.layers.LSTM(nodes, return_sequences=True, input_shape = (timestep,features*batch_size),kernel_regularizer='l2'))\n",
    "    model.add(keras.layers.Dropout(trial.parameters['dropout']))\n",
    "model.add(keras.layers.Dense(1))\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr)\n",
    "model.compile(loss='mse',optimizer=optimizer, metrics=['mae'])\n",
    "\n",
    "history = model.fit(X_train,y_train,epochs=1000, validation_split=0.2,callbacks=early_stop)\n",
    "    \n",
    "model.summary()\n",
    "plot_history(history)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "7af8c0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 5, 28)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "0f1eb5cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 1)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5b8e51",
   "metadata": {},
   "source": [
    "## Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "44c34fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "[loss, mae] = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "6b5a4d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2033914476633072\n"
     ]
    }
   ],
   "source": [
    "print(mae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1813453c",
   "metadata": {},
   "source": [
    "## Predict using data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "b7c6b01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe10ff2b170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe10ff2b170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "#print(test_predictions)\n",
    "tempT = []\n",
    "averages = []\n",
    "for x in range(len(test_predictions)):\n",
    "    tempT = test_predictions[x]\n",
    "    sum = 0\n",
    "    for y in range(len(tempT)):\n",
    "        sum = sum + tempT[y]\n",
    "    avg = sum/len(tempT)\n",
    "    averages.append(avg)\n",
    "               \n",
    "test_predictions = averages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "4aa8e2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.scatter(y_test, test_predictions)\n",
    "plt.xlabel('True Values ')\n",
    "plt.ylabel('Predictions ')\n",
    "plt.axis('equal')\n",
    "plt.xlim(plt.xlim())\n",
    "plt.ylim(plt.ylim())\n",
    "_ = plt.plot([-100, 100], [-100, 100])\n",
    "#plt.savefig('C:/Users/Madi/Desktop/ML/LSTM50.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "a853077c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13949870384798746"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "023b4166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "test_predictionsT = np.transpose(test_predictions)\n",
    "test_predictions = pd.DataFrame(test_predictions,columns=['D2Area'])\n",
    "\n",
    "error = test_predictions - y_test\n",
    "\n",
    "\n",
    "plt.hist(error, bins=25)\n",
    "\n",
    "plt.xlabel(\"Prediction Error\")\n",
    "_ = plt.ylabel(\"Count\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
